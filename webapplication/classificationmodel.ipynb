{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model \n",
    "\n",
    "### Delay Classification Model: Classify whether the flight will be delayed more than 15 minutes [0/1]\n",
    "\n",
    "1. Read the data from the folder.\n",
    "2. Convert to dummy variables.\n",
    "3. Create train-and-test split data and train them in a logistic regression model.\n",
    "4. Create a Random Forest Model with 50 trees and 100 trees to see the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Arrival Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading CSV file in 0.529555082321167 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DAY_OF_WEEK         int64\n",
       "UNIQUE_CARRIER     object\n",
       "ORIGIN             object\n",
       "DEST               object\n",
       "ARR_DELAY         float64\n",
       "DEP_HOUR            int64\n",
       "ARR_HOUR            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Read the data from the folder:\n",
    "\n",
    "tic = time.time()\n",
    "df = pd.read_csv('../python-introduction-th2669/juneairline_data1.csv')\n",
    "toc = time.time()\n",
    "print(\"Finished reading CSV file in \" + str(toc-tic) + \" seconds\")\n",
    "df.head\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preparing data in 27.491552114486694 seconds\n"
     ]
    }
   ],
   "source": [
    "# DATA preparation\n",
    "tic = time.time()\n",
    "# Remove data redundancy\n",
    "df['ARR_HOUR'] = df['ARR_HOUR'].apply(lambda x:0 if x == 24 else x)\n",
    "# Drop rows with Null Values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert to Dummy Variables\n",
    "df = pd.concat([df,pd.get_dummies(df['DAY_OF_WEEK'],drop_first=True,prefix=\"DAY_OF_WEEK\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['UNIQUE_CARRIER'],drop_first=True,prefix=\"UNIQUE_CARRIER\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ORIGIN'],drop_first=True,prefix=\"ORIGIN\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEST'],drop_first=True,prefix=\"DEST\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEP_HOUR'],drop_first=True,prefix=\"DEP_HOUR\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ARR_HOUR'],drop_first=True,prefix=\"ARR_HOUR\")],axis=1)\n",
    "\n",
    "df.drop(['DAY_OF_WEEK','UNIQUE_CARRIER','ORIGIN','DEST','DEP_HOUR','ARR_HOUR'],axis=1,inplace=True)\n",
    "\n",
    "#ARR_DELAY -> Delay Yes or No -> 1 if Delay > 15 minutes, else 0\n",
    "df['ARR_DELAY'] = df['ARR_DELAY'].apply(lambda x:1 if x>=15 else 0)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Finished preparing data in \" + str(toc-tic) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the train and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('ARR_DELAY',axis=1), \n",
    "                                                    df['ARR_DELAY'], test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Train the model in a logistic regression model\n",
    "logmodel_arr = LogisticRegression(penalty='l2')\n",
    "logmodel_arr.fit(X_train,y_train)\n",
    "\n",
    "#Predicting on the Test Set\n",
    "predictions = logmodel_arr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89    114257\n",
      "          1       0.67      0.19      0.30     30018\n",
      "\n",
      "avg / total       0.79      0.81      0.77    144275\n",
      "\n",
      "Accuracy: 0.8125108300121296\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logmodel_arr.pkl', 'wb') as fid:\n",
    "    pickle.dump(logmodel_arr, fid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save a dictionary of the index keys to make the dummy variables out of user input\n",
    "#create a dataframe containing only the categorical variables. In our case, it is the entire dataset except the ARR_DELAY column\n",
    "flightdata = df.drop('ARR_DELAY',axis=1)\n",
    "index_dict = dict(zip(flightdata.columns,range(flightdata.shape[1])))\n",
    "\n",
    "#Save the index_dict into disk\n",
    "with open('flightdata', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try Random Forest Model (n=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, cross_validation, metrics, svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create Random Forest classifier with 50 trees\n",
    "randomforest_arr = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "randomforest_arr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "predictions = randomforest_arr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91    114165\n",
      "          1       0.71      0.53      0.61     30110\n",
      "\n",
      "avg / total       0.85      0.86      0.85    144275\n",
      "\n",
      "Accuracy: 0.857425056316063\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try Random Forest Model (n=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, cross_validation, metrics, svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create Random Forest classifier with 100 trees\n",
    "randomforest_arr = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "randomforest_arr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "predictions = randomforest_arr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91    114165\n",
      "          1       0.72      0.53      0.61     30110\n",
      "\n",
      "avg / total       0.85      0.86      0.85    144275\n",
      "\n",
      "Accuracy: 0.8590053716860163\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('randomforest_arr.pkl', 'wb') as fid:\n",
    "    pickle.dump(randomforest_arr, fid,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Departure Delay with same method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading CSV file in 0.5333318710327148 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DAY_OF_WEEK         int64\n",
       "UNIQUE_CARRIER     object\n",
       "ORIGIN             object\n",
       "DEST               object\n",
       "DEP_DELAY         float64\n",
       "DEP_HOUR            int64\n",
       "ARR_HOUR            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Read the data from the folder:\n",
    "\n",
    "tic = time.time()\n",
    "df = pd.read_csv('../python-introduction-th2669/juneairline_data2.csv')\n",
    "toc = time.time()\n",
    "print(\"Finished reading CSV file in \" + str(toc-tic) + \" seconds\")\n",
    "df.head\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preparing data in 30.257885932922363 seconds\n"
     ]
    }
   ],
   "source": [
    "# DATA preparation\n",
    "tic = time.time()\n",
    "# Remove data redundancy\n",
    "df['ARR_HOUR'] = df['ARR_HOUR'].apply(lambda x:0 if x == 24 else x)\n",
    "# Drop rows with Null Values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert to Dummy Variables\n",
    "df = pd.concat([df,pd.get_dummies(df['DAY_OF_WEEK'],drop_first=True,prefix=\"DAY_OF_WEEK\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['UNIQUE_CARRIER'],drop_first=True,prefix=\"UNIQUE_CARRIER\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ORIGIN'],drop_first=True,prefix=\"ORIGIN\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEST'],drop_first=True,prefix=\"DEST\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['DEP_HOUR'],drop_first=True,prefix=\"DEP_HOUR\")],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ARR_HOUR'],drop_first=True,prefix=\"ARR_HOUR\")],axis=1)\n",
    "\n",
    "df.drop(['DAY_OF_WEEK','UNIQUE_CARRIER','ORIGIN','DEST','DEP_HOUR','ARR_HOUR'],axis=1,inplace=True)\n",
    "\n",
    "#DEP_DELAY -> Delay Yes or No -> 1 if Delay > 15 minutes, else 0\n",
    "df['DEP_DELAY'] = df['DEP_DELAY'].apply(lambda x:1 if x>=15 else 0)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Finished preparing data in \" + str(toc-tic) + \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the train and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('DEP_DELAY',axis=1), \n",
    "                                                    df['DEP_DELAY'], test_size=0.30, \n",
    "                                                    random_state=101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Train the model in a logistic regression model\n",
    "logmodel_dep = LogisticRegression(penalty='l2')\n",
    "logmodel_dep.fit(X_train,y_train)\n",
    "\n",
    "#Predicting on the Test Set\n",
    "predictions = logmodel_dep.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.98      0.89    114638\n",
      "          1       0.69      0.18      0.28     29637\n",
      "\n",
      "avg / total       0.79      0.81      0.77    144275\n",
      "\n",
      "Accuracy: 0.8145971235487783\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logmodel_dep.pkl', 'wb') as fid:\n",
    "    pickle.dump(logmodel_dep, fid,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try Random Forest Model (n=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, cross_validation, metrics, svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create Random Forest classifier with 50 trees\n",
    "randomforest_dep = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "randomforest_dep.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "predictions = randomforest_dep.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90    114638\n",
      "          1       0.64      0.47      0.54     29637\n",
      "\n",
      "avg / total       0.82      0.84      0.83    144275\n",
      "\n",
      "Accuracy: 0.8367977820135158\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try Random Forest Model (n=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, cross_validation, metrics, svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create Random Forest classifier with 100 trees\n",
    "randomforest_dep = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "randomforest_dep.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "predictions = randomforest_dep.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.93      0.90    114638\n",
      "          1       0.65      0.47      0.55     29637\n",
      "\n",
      "avg / total       0.83      0.84      0.83    144275\n",
      "\n",
      "Accuracy: 0.8395286778721193\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "truePos = X_test[((predictions == 1) & (y_test == predictions))]\n",
    "falsePos = X_test[((predictions == 1) & (y_test != predictions))]\n",
    "trueNeg = X_test[((predictions == 0) & (y_test == predictions))]\n",
    "falseNeg = X_test[((predictions == 0) & (y_test != predictions))]\n",
    "\n",
    "TP = truePos.shape[0]\n",
    "FP = falsePos.shape[0]\n",
    "TN = trueNeg.shape[0]\n",
    "FN = falseNeg.shape[0]\n",
    "\n",
    "accuracy = float(TP + TN)/float(TP + TN + FP + FN)\n",
    "print('Accuracy: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that random forest model with 100 trees does not improve the results a lot. It takes longer. Therefore, we choose to use 50 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('randomforest_dep.pkl', 'wb') as fid:\n",
    "    pickle.dump(randomforest_dep, fid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
